<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>VisionAI: Emotion Detection</title>
  <meta name="theme-color" content="#f7f9fc" />

  <style>
    :root {
      --bg:#f7f9fc; --fg:#0f172a; --muted:#64748b; --brand:#0a66c2;
      --card:#ffffff; --border:#e2e8f0; --shadow:0 1px 2px rgba(0,0,0,.06), 0 6px 16px rgba(0,0,0,.08);
      --radius:14px; --maxw:1120px; --tint:#eef6ff; --hint:#e39b07;
      --section-gap:12px;
    }
    body{margin:0;font-family:ui-sans-serif,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Helvetica,Arial;color:var(--fg);background:var(--bg);}
    .container{max-width:var(--maxw);margin:0 auto;padding:clamp(16px,3vw,32px);}
    .title{font-size:clamp(22px,4vw,34px);color:var(--brand);margin:0 0 6px;}
    .subtitle{color:var(--muted);font-size:16px;margin:0 0 12px;}

    .scroll-hint{display:none;}
    @media (max-width:899px){.scroll-hint{display:block;font-size:.95rem;font-style:italic;font-weight:700;color:var(--hint);margin-bottom:6px;}}

    .info-card{background:var(--tint);border:1px solid var(--border);border-radius:var(--radius);box-shadow:var(--shadow);}
    .info-head{border-bottom:1px solid var(--border);padding:14px 18px 10px;}
    .chips{display:flex;flex-wrap:wrap;gap:8px;}
    .chip{font-size:12px;padding:6px 10px;border-radius:999px;border:1px solid var(--border);background:var(--card);color:var(--muted);}
    .info-body{display:grid;grid-template-columns:1fr;row-gap:var(--section-gap);padding:18px 20px;}
    @media (min-width:900px){.info-body{grid-template-columns:1fr 1fr;column-gap:60px;}}
    .info-section h3{font-size:.95rem;margin:0 0 4px;color:var(--fg);}
    .info-section p{margin:0 0 var(--section-gap);line-height:1.48;}
    .info-section p:last-child{margin-bottom:0;}
    .inline-role{font-weight:600;letter-spacing:.3px;}
    .info-full{grid-column:1/-1;}
    @media (min-width:900px){.info-section.info-full{margin-top:6px;}}

    .grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(200px,1fr));gap:clamp(10px,2vw,18px);margin-top:clamp(16px,3vw,30px);}
    figure.card{margin:0;border:1px solid var(--border);background:var(--card);border-radius:var(--radius);overflow:hidden;box-shadow:var(--shadow);transition:transform .12s ease, box-shadow .12s ease;}
    figure.card:hover{transform:translateY(-2px);box-shadow:0 3px 10px rgba(10,102,194,.25),var(--shadow);}
    .media{aspect-ratio:3/4.5;background:var(--card);display:flex;align-items:center;justify-content:center;}
    .media img{width:100%;height:100%;object-fit:contain;object-position:center;display:block;}
    figcaption{padding:10px 12px;font-weight:600;font-size:14px;text-align:center;color:var(--fg);border-top:1px solid var(--border);}
    .note{font-size:clamp(15px,2.8vw,18px);font-style:italic;color:var(--muted);margin-top:40px;max-width:70ch;text-align:left;}
    @media (max-width:768px){.grid{grid-template-columns:repeat(2,1fr);}}
  </style>
</head>
<body>
  <main class="container">
    <h1 class="title">VisionAI: Emotion Detection</h1>

    <section class="info-card" aria-labelledby="overview">
      <div class="info-head">
        <h2 id="overview" class="subtitle" style="margin:0;">Overview</h2>
        <div class="chips">
          <span class="chip">On-device</span><span class="chip">Real-time</span><span class="chip">Privacy-first</span><span class="chip">TFLite + SwiftUI</span>
        </div>
      </div>

      <div class="info-body">
        <div class="info-section">
          <p class="scroll-hint"><strong><em>Scroll down for Demo</em></strong></p>
          <h3>Project overview</h3>
          <p>Mobile app that classifies facial emotions in real time using a TensorFlow Lite model in SwiftUI. Runs fully on-device for speed and privacy.</p>

          <h3>Business impact</h3>
          <p>Delivers quick emotion signals to guide UX decisions and personalization without sending video off the device.</p>
        </div>

        <div class="info-section">
          <h3>My role: <span class="inline-role">Strategy → architecture → build → test</span></h3>
          <p>Trained the model using FERPlus and RAF-DB datasets, optimized it for TensorFlow Lite, and integrated live camera inference in SwiftUI.</p>

          <h3>Scalability</h3>
          <p>Extend to sentiment tracking, adaptive UI feedback, and AR/VR analysis.</p>
        </div>

        <div class="info-section info-full">
          <h3>Technical details</h3><p><em>See below</em></p>
        </div>
      </div>
    </section>

    <h2 class="subtitle" style="margin-top:24px;">Demo</h2>
    <div class="grid">
      <figure class="card"><div class="media"><img src="AppIcon.png" alt="App Icon" loading="lazy"></div><figcaption>App Icon, Deployment</figcaption></figure>
      <figure class="card"><div class="media"><img src="Happy.JPG" alt="Happy" loading="lazy"></div><figcaption>Happy</figcaption></figure>
      <figure class="card"><div class="media"><img src="Sad.JPG" alt="Sad" loading="lazy"></div><figcaption>Sad</figcaption></figure>
      <figure class="card"><div class="media"><img src="Anger.JPG" alt="Anger" loading="lazy"></div><figcaption>Anger</figcaption></figure>
      <figure class="card"><div class="media"><img src="Disgust.JPG" alt="Disgust" loading="lazy"></div><figcaption>Disgust</figcaption></figure>
      <figure class="card"><div class="media"><img src="Neutral.JPG" alt="Neutral" loading="lazy"></div><figcaption>Neutral</figcaption></figure>
      <figure class="card"><div class="media"><img src="Surprise.JPG" alt="Surprise" loading="lazy"></div><figcaption>Surprise</figcaption></figure>
      <figure class="card"><div class="media"><img src="Fear.JPG" alt="Fear" loading="lazy"></div><figcaption>Fear</figcaption></figure>
    </div>

    <!-- Technical details -->
    <section class="info-card" aria-labelledby="details" style="margin-top:26px;">
      <div class="info-head">
        <h2 id="details" class="subtitle" style="margin:0;">Technical details</h2>
        <div class="chips">
          <span class="chip">TensorFlow Lite</span><span class="chip">SwiftUI</span><span class="chip">FERPlus</span><span class="chip">RAF-DB</span><span class="chip">On-device inference</span><span class="chip">Xcode</span>
        </div>
      </div>
      <div class="info-body" style="grid-template-columns:1fr;">
        <ul style="margin:0;padding-left:1.1rem;">
          <li><strong>Data & inputs</strong> – trained the emotion model using FERPlus and RAF-DB images (seven classes), with basic balancing and holdout validation.</li>
          <li><strong>Model & processing</strong> – preprocessing with grayscale/resize; converted to TensorFlow Lite with size/speed optimizations.</li>
          <li><strong>Runtime</strong> – on-device TFLite inference for low-latency predictions; no video leaves the phone.</li>
          <li><strong>App & UI</strong> – SwiftUI interface; AVFoundation camera stream with lightweight frame pipeline.</li>
          <li><strong>Build & deployment</strong> – packaged and installed via Xcode for device testing and demos.</li>
          <li><strong>Privacy & performance</strong> – local inference, small model footprint, and consistent real-time FPS on recent iPhones.</li>
        </ul>
      </div>
    </section>

    <p class="note">If I have to resort to acting for a living, that’s not going to be good for anyone. Just saying.</p>
  </main>
</body>
</html>
